{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `lyra-fr` on SageMaker through Model Packages\n",
    "\n",
    "Developed by <a href=\"https://lighton.ai/\"/>LightOn</a>, `lyra-fr` is the largest language model natively trained in French. `lyra-fr` understands natural language instructions in French, and can perform many tasks in zero-shot or few-shot. If you want to know more about the best ways to prompt large language models, you can have a look at the <a href=\"https://muse-docs.lighton.ai/usecases/english/prompt\">documentation</a>. If you are familiar with the prompting literature, advanced techniques like <a href=\"https://arxiv.org/abs/2201.11903\">Chain of Thought</a> also work with it.\n",
    "\n",
    "Summarizing is as easy as adding *Résumé :* after the relevant text snippet, simply change it to *Mots clés :* to perform keywords extraction instead. The only limit is what you can express in text.\n",
    "\n",
    "For example\n",
    "\n",
    ">Extrais les mots clés de l'article suivant: Le corium est un magma métallique et minéral constitué d'éléments fondus du cœur d'un réacteur nucléaire, puis des minéraux qu'il peut absorber lors de son trajet. Le terme « corium » est un néologisme formé de core (en anglais, pour le cœur d'un réacteur nucléaire), suivi du suffixe -ium présent dans le nom de nombreux éléments du tableau périodique des éléments : lithium, calcium, uranium, plutonium, hélium, strontium, etc. Initialement constitué du combustible nucléaire (principalement de l'oxyde d'uranium enrichi), des éléments de l'assemblage combustible et des divers équipements du cœur (barres de contrôle, instrumentation) ou de la paroi de la cuve du réacteur avec lesquels il entre en contact, il se forme à très haute température (environ 3 000 °C, température de fusion de l'oxyde d'uranium) quand le cœur n'est plus refroidi, comme lors d'accidents nucléaires tels ceux de Three Mile Island, de Tchernobyl, ou de Fukushima.\n",
    ">\n",
    ">Mots-clés : corium, réacteur nucléaire, fusion du cœur\n",
    "\n",
    "This sample notebook shows you how to deploy `lyra-fr` using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "## Pre-requisites:\n",
    "1. Before running this notebook, please make sure you got this notebook from the model catalog on SageMaker AWS Management Console.\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**.\n",
    "\n",
    "## Contents:\n",
    "1. [Select model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    \n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select to the model package\n",
    "Confirm that you received this notebook from model catalog on SageMaker AWS Management Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for Model Packages (initially only us-east-1 and eu-west-1 is supported)\n",
    "model_package_map = {\n",
    "    \"us-east-1\": \"arn:aws:sagemaker:us-east-1:865070037744:model-package/lyra-fr-13be5bdcc7b73aca97c39905991719ed\",\n",
    "    \"eu-west-1\": \"arn:aws:sagemaker:eu-west-1:985815980388:model-package/lyra-fr-13be5bdcc7b73aca97c39905991719ed\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting git+https://github.com/lightonai/lightonmuse-sagemaker-sdk.git\n",
      "  Cloning https://github.com/lightonai/lightonmuse-sagemaker-sdk.git to /tmp/pip-req-build-hcjrrdma\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lightonai/lightonmuse-sagemaker-sdk.git /tmp/pip-req-build-hcjrrdma\n",
      "  Resolved https://github.com/lightonai/lightonmuse-sagemaker-sdk.git to commit 97ba0085b56bf988b58962285600f78a4c6830ba\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3==1.26.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from lightonsage==0.1.dev4+g97ba008) (1.26.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3==1.26.0->lightonsage==0.1.dev4+g97ba008) (1.29.9)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3==1.26.0->lightonsage==0.1.dev4+g97ba008) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from boto3==1.26.0->lightonsage==0.1.dev4+g97ba008) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.0->boto3==1.26.0->lightonsage==0.1.dev4+g97ba008) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.0->boto3==1.26.0->lightonsage==0.1.dev4+g97ba008) (1.26.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.0->boto3==1.26.0->lightonsage==0.1.dev4+g97ba008) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/lightonai/lightonmuse-sagemaker-sdk.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightonsage as lsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "if region not in model_package_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "model_package_arn = model_package_map[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "runtime_sm_client = boto3.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"lyra-fr\"\n",
    "\n",
    "content_type = \"application/json\"\n",
    "\n",
    "real_time_inference_instance_type = (\n",
    "    \"ml.p4d.24xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateEndpointConfig operation: Cannot create already existing endpoint configuration \"arn:aws:sagemaker:us-east-1:372939818206:endpoint-config/lyra-fr\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23734/1402728190.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Deploy the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_time_inference_instance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_data_download_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, **kwargs)\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0masync_inference_config_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masync_inference_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_request_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m         self.sagemaker_session.endpoint_from_production_variants(\n\u001b[0m\u001b[1;32m   1197\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m             \u001b[0mproduction_variants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproduction_variant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict)\u001b[0m\n\u001b[1;32m   3679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3680\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating endpoint-config with name %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3681\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m                 )\n\u001b[1;32m    514\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateEndpointConfig operation: Cannot create already existing endpoint configuration \"arn:aws:sagemaker:us-east-1:372939818206:endpoint-config/lyra-fr\"."
     ]
    }
   ],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name, model_data_download_timeout=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details on the parameters of the endpoint Create, see the <a href=\"https://muse-docs.lighton.ai/api/endpoints/create\">docs</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"text\": \"Génère une liste d'idées d'articles sur l'aquarelle.\\n1. L'aquarelle dans l'histoire\\n2.\", \n",
    "    \"params\": {\n",
    "        \"n_tokens\": 43, \n",
    "        \"seed\": 0\n",
    "    }, \n",
    "    \"endpoint\":\"create\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Add code snippet that shows the payload contents>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=model_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(payload),\n",
    " \n",
    ")\n",
    "\n",
    "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génère une liste d'idées d'articles sur l'aquarelle.\n",
      "1. L'aquarelle dans l'histoire\n",
      "2. 🤖  L'histoire de l'aquarelle\n",
      "3. Le matériel de l'aquarelliste\n",
      "4. Les pigments utilisés en aquarelle\n",
      "5. Les encres en aquarelle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{payload['text']} 🤖 {output['outputs'][0][0]['completions'][0]['output_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have seen above how to use JSON payloads to invoke an endpoint, now let's use the Python SDK. Using the Python SDK provides a better, more streamlined user experience, and it is recommeneded for experimentation.\n",
    "\n",
    "The Python SDK takes care for you of formatting the input, calling the endpoint, and unpacking the output. There is one class per endpoint: `Create`, `Analyse`, `Select`, `Embed`, `Compare` and `Tokenize`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Create for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should describe the task you want to carry out in French, for example in the following: *Détermine si ces commentaires expriment des avis positifs, négatifs ou mitigés.*\n",
    "\n",
    "In addition, providing examples improves the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = lsage.Create(\"lyra-fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Détermine si ces commentaires expriment des avis positifs, négatifs ou mitigés.\n",
      "----------\n",
      "Commentaire : \"Désolé mais je n'ai pas de compliment à faire à ce garage. Je me trouvais sur Saint-Étienne j'étais crevé avec bien sur un clou dans le pneu, l employé me dit qu il ne pouvais pas me dépanner, qu'il fallait que je gonfle mon pneu à 2.4 je suis redescendu à Roanne il a fallu que je arrête mi-chemin pour gonfler mon pneu. Chercher l'erreur\"\n",
      "Ce commentaire exprime un avis négatif.\n",
      "----------\n",
      "Commentaire : \"Garage avec un service bien meilleur que les concurrents.Ça aurait pu être parfait, si un léger coup de nettoyage sur les jantes lors du remplacement de mes pneus avait été effectué.Mes jantes était pour le coup plus sales qu'à l'arrivée à cause du liquide utilisé pour le montage des pneus qui n'a pas été essuyé.Mais après tout ça n'est qu'un détail bonne expérience en général.Je commande !\"\n",
      "Ce commentaire exprime un avis positif.\n",
      "----------\n",
      "Commentaire : \"C'est correct mais des employés pas forcément tous très bien qualifiés\"\n",
      "Ce commentaire exprime un avis mitigé.\n",
      "----------\n",
      "Commentaire : \"Garantie de batterie contraignante et compliquée, du marketing abusif. Si elle est défaillante, on vous la change, mais on vous fait payer la main d'œuvre de remplacement !\"\n",
      "Ce commentaire exprime un avis négatif.\n",
      "----------\n",
      "Commentaire : \"Bon accueil, heure de rendez-vous respecté et le prix de la révision bien moins cher que dans un garage de marque de voiture, prochaine révision ou n’importe quel autre service je le ferai dans chez Norauto, très bon garage.\"\n",
      "Ce commentaire exprime un avis positif.\n",
      "----------\n",
      "Commentaire: \"Excellente enseigne. Personnel compétent et agréable. Je mets cette adresse en favori.\"\n",
      "Ce commentaire exprime un avis 🤖  positif.\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = examples = f\"\"\"Détermine si ces commentaires expriment des avis positifs, négatifs ou mitigés.\n",
    "----------\n",
    "Commentaire : \\\"Désolé mais je n'ai pas de compliment à faire à ce garage. Je me trouvais sur Saint-Étienne j'étais crevé avec bien sur un clou dans le pneu, l employé me dit qu il ne pouvais pas me dépanner, qu'il fallait que je gonfle mon pneu à 2.4 je suis redescendu à Roanne il a fallu que je arrête mi-chemin pour gonfler mon pneu. Chercher l'erreur\\\"\n",
    "Ce commentaire exprime un avis négatif.\n",
    "----------\n",
    "Commentaire : \\\"Garage avec un service bien meilleur que les concurrents.Ça aurait pu être parfait, si un léger coup de nettoyage sur les jantes lors du remplacement de mes pneus avait été effectué.Mes jantes était pour le coup plus sales qu'à l'arrivée à cause du liquide utilisé pour le montage des pneus qui n'a pas été essuyé.Mais après tout ça n'est qu'un détail bonne expérience en général.Je commande !\\\"\n",
    "Ce commentaire exprime un avis positif.\n",
    "----------\n",
    "Commentaire : \\\"C'est correct mais des employés pas forcément tous très bien qualifiés\\\"\n",
    "Ce commentaire exprime un avis mitigé.\n",
    "----------\n",
    "Commentaire : \\\"Garantie de batterie contraignante et compliquée, du marketing abusif. Si elle est défaillante, on vous la change, mais on vous fait payer la main d'œuvre de remplacement !\\\"\n",
    "Ce commentaire exprime un avis négatif.\n",
    "----------\n",
    "Commentaire : \\\"Bon accueil, heure de rendez-vous respecté et le prix de la révision bien moins cher que dans un garage de marque de voiture, prochaine révision ou n’importe quel autre service je le ferai dans chez Norauto, très bon garage.\\\"\n",
    "Ce commentaire exprime un avis positif.\n",
    "----------\n",
    "Commentaire: \\\"Excellente enseigne. Personnel compétent et agréable. Je mets cette adresse en favori.\\\"\n",
    "Ce commentaire exprime un avis\"\"\"\n",
    "outputs, costs, request_id = creator(few_shot_prompt, stop_words=[\".\", \"\\n\"])\n",
    "print(f\"{few_shot_prompt} 🤖 {outputs[0]['completions'][0]['output_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Select for review classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = lsage.Select(\"lyra-fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Étant donné un commentaire et la catégorie à laquelle il appartient, détermine la sous-catégorie la plus appropriée.\n",
    "\n",
    "Commentaire : \\\"Venu pour faire réparer ma roue crevée, la conseillière a rapidement constater que le pneu n'est pas réparable. Elle m'a proposé des pneus équivalents et pris rdv pour l'après-midi, car un samedi matin, le centre était saturé. Lors de l'arrivée au rdv, prise en charge rapide et 30 min plus tard, le véhicule était prêt - Avertissement par SMS. Même lors du paiement, l'hôte de caisse aura été agréable.Excellent accueil et super boulot\\\"\n",
    "Catégorie :\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Étant donné un commentaire et la catégorie à laquelle il appartient, détermine la sous-catégorie la plus appropriée.\n",
      "\n",
      "Commentaire : \"Venu pour faire réparer ma roue crevée, la conseillière a rapidement constater que le pneu n'est pas réparable. Elle m'a proposé des pneus équivalents et pris rdv pour l'après-midi, car un samedi matin, le centre était saturé. Lors de l'arrivée au rdv, prise en charge rapide et 30 min plus tard, le véhicule était prêt - Avertissement par SMS. Même lors du paiement, l'hôte de caisse aura été agréable.Excellent accueil et super boulot\"\n",
      "Catégorie : 🤖 accueil et conseils\n"
     ]
    }
   ],
   "source": [
    "outputs, costs, request_id = selector(reference=prompt, candidates=[\"accueil et conseils\", \"prise rendez-vous\"])\n",
    "print(f\"{prompt} 🤖 {outputs[0]['best']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
